from transformers import pipeline, MarianMTModel, MarianTokenizer
import tempfile
import os
import logging
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

_translator = None
_translator_loading = False
_MODEL_DIR = os.path.join(os.path.dirname(__file__), "saved_model")

def check_model_exists():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    if not os.path.exists(_MODEL_DIR):
        logger.error(f"‚ùå –ü–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—å—é –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {_MODEL_DIR}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–∞–ø–∫—É (model/ –∏ tokenizer/)
    tokenizer_path = os.path.join(_MODEL_DIR, "tokenizer")
    model_path = os.path.join(_MODEL_DIR, "model")
    
    has_structured = os.path.exists(tokenizer_path) and os.path.exists(model_path)
    
    if not has_structured:
        logger.error(f"‚ùå –í –ø–∞–ø–∫–µ '{_MODEL_DIR}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ–¥–ø–∞–ø–∫–∏ model/ –∏ tokenizer/")
        logger.error("–û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:")
        logger.error("  saved_model/")
        logger.error("  ‚îú‚îÄ‚îÄ model/")
        logger.error("  ‚îÇ   ‚îú‚îÄ‚îÄ config.json")
        logger.error("  ‚îÇ   ‚îî‚îÄ‚îÄ pytorch_model.bin")
        logger.error("  ‚îî‚îÄ‚îÄ tokenizer/")
        logger.error("      ‚îú‚îÄ‚îÄ vocab.json")
        logger.error("      ‚îî‚îÄ‚îÄ tokenizer_config.json")
        return False
    
    logger.info(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞ –≤: {_MODEL_DIR}")
    return True

def get_translator():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏"""
    global _translator, _translator_loading
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
    if not check_model_exists():
        return None
    
    if _translator is not None:
        logger.info("‚úÖ –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
        return _translator
    
    if _translator_loading:
        logger.warning("‚ö†Ô∏è –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —É–∂–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∑–∞–≥—Ä—É–∑–∫–∏, –∂–¥—ë–º...")
        while _translator_loading:
            time.sleep(1)
        return _translator
    
    try:
        logger.info("üîÑ –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞...")
        _translator_loading = True
        start_time = time.time()
        
        import warnings
        warnings.filterwarnings("ignore")
        
        # –ü—É—Ç–∏ –∫ –ø–æ–¥–ø–∞–ø–∫–∞–º
        tokenizer_path = os.path.join(_MODEL_DIR, "tokenizer")
        model_path = os.path.join(_MODEL_DIR, "model")
        
        logger.info(f"üìÇ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏–∑: {tokenizer_path}")
        logger.info(f"üìÇ –ú–æ–¥–µ–ª—å –∏–∑: {model_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–∞–∫ –≤ –≤–∞—à–µ–º –ø—Ä–∏–º–µ—Ä–µ
        tokenizer = MarianTokenizer.from_pretrained(tokenizer_path)
        logger.info("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        model = MarianMTModel.from_pretrained(model_path)
        logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –°–æ–∑–¥–∞–µ–º pipeline
        _translator = pipeline(
            "translation",
            model=model,
            tokenizer=tokenizer,
            device=-1,  # CPU
            src_lang="en",
            tgt_lang="ru",
            max_length=200,
            truncation=True
        )
        
        elapsed = time.time() - start_time
        logger.info(f"‚úÖ Pipeline —Å–æ–∑–¥–∞–Ω –∑–∞ {elapsed:.1f} —Å–µ–∫—É–Ω–¥")
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥
        test_text = "Hello world"
        try:
            test_result = _translator(test_text)[0]['translation_text']
            logger.info(f"üß™ –¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥: '{test_text}' -> '{test_result}'")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
        
    except ImportError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        logger.error("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install transformers torch sentencepiece")
        _translator = None
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        _translator = None
    finally:
        _translator_loading = False
    
    return _translator

def translate_subtitles(srt_path: str) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥ SRT —Ñ–∞–π–ª–∞ —Å EN –Ω–∞ RU"""
    logger.info(f"üéØ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥: {srt_path}")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫
    translator = get_translator()
    if translator is None:
        logger.error("‚ùå –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        return srt_path
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    try:
        with open(srt_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {e}")
        return srt_path
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
    translated_lines = []
    for line in lines:
        line = line.strip()
        if not line or line.isdigit() or '-->' in line:
            translated_lines.append(line + '\n')
        else:
            try:
                translated = translator(line)[0]['translation_text']
                translated_lines.append(translated + '\n')
                logger.debug(f"‚úì '{line[:30]}...' -> '{translated[:30]}...'")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫–∏: {e}")
                translated_lines.append(line + '\n')
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    try:
        with tempfile.NamedTemporaryFile(suffix='.srt', delete=False, mode='w', encoding='utf-8') as tmp:
            for line in translated_lines:
                tmp.write(line)
            return tmp.name
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
        return srt_path
